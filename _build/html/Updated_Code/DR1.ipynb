{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reduction 1\n",
    "\n",
    "**Sanity Check / Merging**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import glob\n",
    "from functools import reduce\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.gridspec as gridspec\n",
    "from datetime import datetime\n",
    "from IPython.core.display import SVG\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Parameters\n",
    "\n",
    "$\\color{red}{\\text{Implement manually !}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 Date\n",
    "date = \"2020_09_15\"\n",
    "\n",
    "# 0.2 XP\n",
    "XP = \"XP_1-1\"\n",
    "\n",
    "# 0.3 Sample type\n",
    "spl = \"ASW\"\n",
    "\n",
    "# 0.4 Deposition Temperature\n",
    "Tdep = \"20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Ramp\n",
    "\n",
    "$\\color{red}{\\text{Implement manually !}}$\n",
    "\n",
    "### Full Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_ramp = []\n",
    "\n",
    "T_ramp.append(\n",
    "        \n",
    "        {\n",
    "            'Sample' : str(spl),\n",
    "            'Date' : str(date),\n",
    "            '20' :  \"\",\n",
    "            '30' : \"\",\n",
    "            '40' : numpy.arange(1, 3, 1).tolist(),\n",
    "            '50' : \"\",\n",
    "            '60' : numpy.arange(3, 13, 1).tolist(),\n",
    "            '70' : \"\",\n",
    "            '80' : numpy.arange(13, 23, 1).tolist(),\n",
    "            '90' : \"\",\n",
    "            '100' : numpy.arange(23, 35, 1).tolist(),\n",
    "            '110' :\"\",\n",
    "            '120' : numpy.arange(35, 45, 1).tolist(),\n",
    "            '125' : \"\",\n",
    "            '130' : numpy.arange(45, 55, 1).tolist(),\n",
    "            '132' : \"\",\n",
    "            '134' : \"\",\n",
    "            '135' : numpy.arange(55, 65, 1).tolist(),\n",
    "            '136' : \"\",\n",
    "            '137' : \"\",\n",
    "            '138' : \"\",\n",
    "            '140' : numpy.arange(65, 76, 1).tolist(),\n",
    "            '142' : \"\",\n",
    "            '145' : numpy.arange(76, 166, 1).tolist(),\n",
    "            '150' :\"\",\n",
    "            '155' : \"\",\n",
    "            '160' : \"\",\n",
    "            '180' : \"\",\n",
    "            '200' : \"\",\n",
    "\n",
    "            })\n",
    "\n",
    "#T_ramp\n",
    "\n",
    "T_ramp_df = pd.DataFrame(T_ramp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T_ramp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Data to csv\n",
    "\n",
    "Only if date is not already present into XP_Ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XP_Ramp_df = pd.read_csv('..\\DATA\\DATA-Processing\\PAC\\XP_list_test.csv')\n",
    "\n",
    "XP_Date = []\n",
    "\n",
    "XP_Date = str(XP_Ramp_df['Date'])\n",
    "\n",
    "\n",
    "if date in XP_Date:\n",
    "    print(\"Not appended\")\n",
    "else:\n",
    "    T_ramp_df.to_csv('..\\DATA\\DATA-Processing\\PAC\\XP_list_test.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T ramp for reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [0,1,2,3]\n",
    "j = [\"20\",\"130\",\"140\",\"160\"]\n",
    "\n",
    "Tdictionary = dict(zip(j, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isotherm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iso = widgets.Checkbox(\n",
    "      value=False,\n",
    "      description='Isotherm',\n",
    "      disabled=False,\n",
    "      indent=False\n",
    ")\n",
    "\n",
    "display(Iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tiso1 = \"130\"\n",
    "\n",
    "#k = [10,50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800] \n",
    "#l = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\"]\n",
    "\n",
    "#Isodic1 = dict(zip(l, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DR1 (Proper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"..\\DATA\\DATA-RAW\\PAC\\{}/{}/*_smooth.csv\".format(XP,date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empty Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List within which all the individual scans will be added prior to merging\n",
    "All_data_frame = []\n",
    "\n",
    "# List where all the \"data annex\" (ie max absorbance ...), will be stored \n",
    "data_anex = []\n",
    "\n",
    "#Temperature Ramp that the sample experienced (need to be entered manually later)\n",
    "T_ramp = []\n",
    "\n",
    "# Data annex values\n",
    "data_max = []\n",
    "minimum_1 = []\n",
    "minimum_1_index = []\n",
    "minimum_2 = []\n",
    "minimum_2_index = []\n",
    "minimum_3 = []\n",
    "minimum_3_index = []\n",
    "minimum_4 = []\n",
    "minimum_4_index = []\n",
    "minimum_5 = []\n",
    "minimum_5_index = []\n",
    "minimum_6 = []\n",
    "minimum_6_index = []\n",
    "\n",
    "maximum = []\n",
    "maximum_index = []\n",
    "\n",
    "# iterator\n",
    "\n",
    "file_number = 1\n",
    "\n",
    "#for loop\n",
    "\n",
    "for file in glob.glob(file_path):\n",
    "\n",
    "    df = pd.read_csv(file, names=[\"Wavenumber\", str(spl)+\"_\"+str(date)+\"_\"+str(file_number)])\n",
    "    \n",
    "    All_data_frame.append(df) \n",
    "\n",
    "    #Min 4000 - 3800 wavenumber\n",
    "    \n",
    "    min1 = df.iloc[6223:6639,1].astype(float).min()\n",
    "    min1_index= df.iloc[6223:6639,1].astype(float).idxmin()\n",
    "    \n",
    "    #Min 3000 - 2800 wavenumber\n",
    "    \n",
    "    min2 = df.iloc[4149:4564,1].astype(float).min()\n",
    "    min2_index = df.iloc[4149:4564,1].astype(float).idxmin()\n",
    "    \n",
    "    #Min 2800 - 2700 wavenumber\n",
    "    \n",
    "    min3 = df.iloc[3941:4149,1].astype(float).min()\n",
    "    min3_index= df.iloc[3941:4149,1].astype(float).idxmin()\n",
    "    \n",
    "    #Min 2000 - 1900 wavenumber\n",
    "    \n",
    "    min4 = df.iloc[2282:2490,1].astype(float).min()\n",
    "    min4_index = df.iloc[2282:2490,1].astype(float).idxmin()\n",
    "    \n",
    "    #Min 2800 - 2700 wavenumber\n",
    "    \n",
    "    min3 = df.iloc[3941:4149,1].astype(float).min()\n",
    "    min3_index= df.iloc[3941:4149,1].astype(float).idxmin()\n",
    "    \n",
    "    #Min 2000 - 1900 wavenumber\n",
    "    \n",
    "    min4 = df.iloc[2282:2490,1].astype(float).min()\n",
    "    min4_index = df.iloc[2282:2490,1].astype(float).idxmin()\n",
    "    \n",
    "    #Min 1900 - 1800 wavenumber\n",
    "    \n",
    "    min5 = df.iloc[2075:2282,1].astype(float).min()\n",
    "    min5_index= df.iloc[2075:2282,1].astype(float).idxmin()\n",
    "    \n",
    "    #Min 1300 - 800 wavenumber\n",
    "    \n",
    "    min6 = df.iloc[0:1038,1].astype(float).min()\n",
    "    min6_index = df.iloc[0:1038,1].astype(float).idxmin()\n",
    "    \n",
    "    maxi = df.iloc[4149:6639,1].astype(float).max()\n",
    "    maxi_index= df.iloc[4149:6639,1].astype(float).idxmax()\n",
    "    \n",
    "\n",
    "    #Wavenumber.append(Wav)    \n",
    "    #RAW_data.append(RAW)\n",
    "    \n",
    "    minimum_1.append(min1)\n",
    "    minimum_1_index.append(min1_index)\n",
    "    \n",
    "    minimum_2.append(min2)\n",
    "    minimum_2_index.append(min2_index)\n",
    "    \n",
    "    minimum_3.append(min3)\n",
    "    minimum_3_index.append(min3_index)\n",
    "    \n",
    "    minimum_4.append(min3)\n",
    "    minimum_4_index.append(min3_index)\n",
    "    \n",
    "    minimum_5.append(min5)\n",
    "    minimum_5_index.append(min5_index)\n",
    "    \n",
    "    minimum_6.append(min6)\n",
    "    minimum_6_index.append(min6_index)\n",
    "    \n",
    "    maximum.append(maxi)\n",
    "    maximum_index.append(maxi_index)\n",
    "        \n",
    "    data_anex.append(\n",
    "        \n",
    "        {\n",
    "\n",
    "            'Name' : str(spl)+\"_\"+str(date)+\"_\" + str(file_number),\n",
    "            'min1' : min1,\n",
    "            'index1' :  min1_index,\n",
    "            'min2' : min2,\n",
    "            'index2' :  min2_index,\n",
    "            'min3' : min3,\n",
    "            'index3' :  min3_index,\n",
    "            'min4' : min4,\n",
    "            'index4' :  min4_index,\n",
    "            'min5' : min5,\n",
    "            'index5' :  min5_index,\n",
    "            'min6' : min6,\n",
    "            'index6' :  min6_index,\n",
    "            'max' : maxi,\n",
    "            'max_index' :  maxi_index,\n",
    "        })\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    file_number +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
