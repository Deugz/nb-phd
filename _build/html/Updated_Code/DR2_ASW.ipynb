{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reduction 2 - ASW\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Follow the DR1 Reduction step\n",
    "\n",
    "**Baseline Correction**\n",
    "\n",
    "3 different subnotebook\n",
    "- **ASW**\n",
    "- C2H6\n",
    "- C2H6_ASW\n",
    "\n",
    "## Workflow\n",
    "\n",
    "**Plan**\n",
    "\n",
    "- Imports\n",
    "- Input Parameters\n",
    "- Load data\n",
    "- T Ramp for reduction\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Describe the libraries we're using here. If there's something unusual, explain what the library is, and why we need it.\n",
    "\n",
    "- numpy to handle array functions\n",
    "- math\n",
    "- matplotlib.pyplot for plotting data\n",
    "- pandas\n",
    "- glob\n",
    "- functools\n",
    "- ipywidgets\n",
    "- ...\n",
    "\n",
    "Check if they are all of use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import math\n",
    "from math import isnan\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import glob\n",
    "from functools import reduce\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.gridspec as gridspec\n",
    "from datetime import datetime\n",
    "from IPython.core.display import SVG\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Parameters\n",
    "\n",
    "$\\color{red}{\\text{Implement manually !}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 Date\n",
    "date = \"2020_09_15\"\n",
    "\n",
    "# 0.2 XP\n",
    "XP = \"XP_1-1\"\n",
    "\n",
    "# 0.3 Sample type\n",
    "spl = \"ASW\"\n",
    "\n",
    "# 0.4 Deposition Temperature\n",
    "Tdep = \"20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All_RAW_df\n",
    "\n",
    "All_RAW_df = pd.read_csv(\"..\\..\\DATA\\DATA-Processing\\PAC\\{}/Samples/{}/Data/DR/DR1_{}_All-scans.csv\".format(XP,date,date))\n",
    "\n",
    "All_RAW_df = All_RAW_df.iloc[:,1:]\n",
    "\n",
    "# data_annex\n",
    "data_annex = pd.read_csv(\"..\\..\\DATA\\DATA-Processing\\PAC\\{}/Samples/{}/Data/DR/DR1_{}_data_annex.csv\".format(XP,date,date))\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>min1</th>\n",
       "      <th>index1</th>\n",
       "      <th>min2</th>\n",
       "      <th>index2</th>\n",
       "      <th>min3</th>\n",
       "      <th>index3</th>\n",
       "      <th>min4</th>\n",
       "      <th>index4</th>\n",
       "      <th>min5</th>\n",
       "      <th>...</th>\n",
       "      <th>maxA0w</th>\n",
       "      <th>maxBi</th>\n",
       "      <th>maxB</th>\n",
       "      <th>maxBw</th>\n",
       "      <th>maxCi</th>\n",
       "      <th>maxC</th>\n",
       "      <th>maxCw</th>\n",
       "      <th>Int_A</th>\n",
       "      <th>Int_C</th>\n",
       "      <th>Int_N_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASW_2020_09_15_1</td>\n",
       "      <td>-0.017293</td>\n",
       "      <td>6630</td>\n",
       "      <td>-0.009476</td>\n",
       "      <td>4293</td>\n",
       "      <td>-0.009151</td>\n",
       "      <td>4147</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>2482</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>3270.249</td>\n",
       "      <td>2936</td>\n",
       "      <td>0.008422</td>\n",
       "      <td>2215.361</td>\n",
       "      <td>1777</td>\n",
       "      <td>0.022221</td>\n",
       "      <td>1656.579</td>\n",
       "      <td>96.292003</td>\n",
       "      <td>6.703636</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASW_2020_09_15_2</td>\n",
       "      <td>-0.017489</td>\n",
       "      <td>6636</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>4161</td>\n",
       "      <td>-0.009001</td>\n",
       "      <td>4132</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>2480</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>...</td>\n",
       "      <td>3246.143</td>\n",
       "      <td>2976</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>2234.646</td>\n",
       "      <td>1754</td>\n",
       "      <td>0.021662</td>\n",
       "      <td>1645.490</td>\n",
       "      <td>111.470194</td>\n",
       "      <td>7.622334</td>\n",
       "      <td>115.762670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASW_2020_09_15_3</td>\n",
       "      <td>-0.017849</td>\n",
       "      <td>6636</td>\n",
       "      <td>-0.009715</td>\n",
       "      <td>4151</td>\n",
       "      <td>-0.009664</td>\n",
       "      <td>4132</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>2463</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>...</td>\n",
       "      <td>3233.125</td>\n",
       "      <td>2974</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>2233.682</td>\n",
       "      <td>1691</td>\n",
       "      <td>0.021226</td>\n",
       "      <td>1615.116</td>\n",
       "      <td>112.359014</td>\n",
       "      <td>8.424437</td>\n",
       "      <td>116.685717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASW_2020_09_15_4</td>\n",
       "      <td>-0.006971</td>\n",
       "      <td>6630</td>\n",
       "      <td>-0.004298</td>\n",
       "      <td>4149</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>4120</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>2473</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>...</td>\n",
       "      <td>3228.304</td>\n",
       "      <td>2976</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>2234.646</td>\n",
       "      <td>1574</td>\n",
       "      <td>0.013023</td>\n",
       "      <td>1558.708</td>\n",
       "      <td>53.700867</td>\n",
       "      <td>4.010565</td>\n",
       "      <td>55.768771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name      min1  index1      min2  index2      min3  index3  \\\n",
       "0  ASW_2020_09_15_1 -0.017293    6630 -0.009476    4293 -0.009151    4147   \n",
       "1  ASW_2020_09_15_2 -0.017489    6636 -0.008995    4161 -0.009001    4132   \n",
       "2  ASW_2020_09_15_3 -0.017849    6636 -0.009715    4151 -0.009664    4132   \n",
       "3  ASW_2020_09_15_4 -0.006971    6630 -0.004298    4149 -0.004222    4120   \n",
       "\n",
       "       min4  index4      min5  ...    maxA0w  maxBi      maxB     maxBw  \\\n",
       "0  0.001203    2482  0.001967  ...  3270.249   2936  0.008422  2215.361   \n",
       "1  0.002430    2480  0.003482  ...  3246.143   2976  0.012062  2234.646   \n",
       "2  0.001595    2463  0.003063  ...  3233.125   2974  0.012331  2233.682   \n",
       "3  0.002220    2473  0.002968  ...  3228.304   2976  0.006884  2234.646   \n",
       "\n",
       "   maxCi      maxC     maxCw       Int_A     Int_C     Int_N_A  \n",
       "0   1777  0.022221  1656.579   96.292003  6.703636  100.000000  \n",
       "1   1754  0.021662  1645.490  111.470194  7.622334  115.762670  \n",
       "2   1691  0.021226  1615.116  112.359014  8.424437  116.685717  \n",
       "3   1574  0.013023  1558.708   53.700867  4.010565   55.768771  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All_RAW_df\n",
    "data_annex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPRESS UNNAMED COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T ramp for reduction\n",
    "\n",
    "$\\color{red}{\\text{Find a new method to generate Tdictionnary from XP_list_test}}$\n",
    "\n",
    "to replace the manually done dictionnary:\n",
    "\n",
    "i = [0,1,2,3]\n",
    "\n",
    "j = [\"20\",\"130\",\"140\",\"160\"]\n",
    "\n",
    "Tdictionary = dict(zip(j, i))\n",
    "\n",
    "\n",
    "**Generate dictionary from df** <br>\n",
    "- <a href=\"https://stackoverflow.com/questions/26716616/convert-a-pandas-dataframe-to-a-dictionary\">Stack-Overflow</a>\n",
    "    \n",
    "\n",
    "- 1. Slice df to only obtain the date we are interested in - OK\n",
    "- 2. Set-up date as index - OK\n",
    "- 3. Transpose - OK\n",
    "- 4. create a dictionnary - OK\n",
    "\n",
    "- Select only the second value in list (where multiples item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "XP_Ramp_df = pd.read_csv('..\\..\\DATA\\DATA-Processing\\PAC\\XP_list_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XP_Ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Date</th>\n",
       "      <th>2020_09_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Date 2020_09_15\n",
       "20          [1]\n",
       "130         [2]\n",
       "140         [3]\n",
       "160         [4]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XP_Ramp_df_date = XP_Ramp_df.loc[XP_Ramp_df['Date'] == date]\n",
    "\n",
    "XP_Ramp_df_date2 = XP_Ramp_df_date.set_index(\"Date\")\n",
    "\n",
    "#XP_Ramp_df_date2\n",
    "\n",
    "XP_Ramp_df_T = XP_Ramp_df_date2.T\n",
    "\n",
    "#XP_Ramp_df_T\n",
    "\n",
    "XP_Ramp_df_T_f = XP_Ramp_df_T.iloc[1: , :]\n",
    "\n",
    "#XP_Ramp_df_T_f\n",
    "\n",
    "XP_Ramp_df_T_f2=XP_Ramp_df_T_f.dropna()\n",
    "\n",
    "XP_Ramp_df_T_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020_09_15': {'20': '[1]', '130': '[2]', '140': '[3]', '160': '[4]'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tdictionary = XP_Ramp_df_T_f2.to_dict('dict')\n",
    "\n",
    "Tdictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Chop the data </u>\n",
    "\n",
    "Because ASW Sample, Data is choped in 3 range:\n",
    "\n",
    "- A: OH stretch : (4000 - 2800 cm-1)\n",
    "- B: Combination bands : (2800 - 1900 cm-1)\n",
    "- C: Bending modes : (1900 - 800 cm-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OH Stretch\n",
    "\n",
    "DR1_A_df = All_RAW_df[4150:6639]\n",
    "#DR1_A_df\n",
    "\n",
    "# Combination Bands\n",
    "\n",
    "DR1_B_df = All_RAW_df[2282:4150]\n",
    "#DR1_B_df\n",
    "\n",
    "# Bending Modes\n",
    "\n",
    "DR1_C_df = All_RAW_df[0:2282]\n",
    "#DR1_C_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Background function definition </u>\n",
    "\n",
    "### Minimum (single point) within a range\n",
    "\n",
    "Here we select a minimum within a predefined range (stored in data_annex). \n",
    "\n",
    "\n",
    "Idea for latter: Try to not select an individual point as minimum but a local minimum with a rolling average\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxA = []\n",
    "maxAi = []\n",
    "\n",
    "# We supress the first column (Wavenumber)\n",
    "\n",
    "DR1_A_df = DR1_A_df.T.iloc[1:].T\n",
    "DR1_B_df = DR1_B_df.T.iloc[1:].T\n",
    "DR1_C_df = DR1_C_df.T.iloc[1:].T\n",
    "\n",
    "# Now compute a new DataFrame indexed by the file names with rows that contain the\n",
    "# minimum value and the index of that minimum value within specific row ranges\n",
    "# of the column in data corresponding to the filename.\n",
    "dataStats = pd.DataFrame.from_dict(\n",
    "  dict(min1=All_RAW_df.T.iloc[1:].T.iloc[6223:6639].min(axis=0), # min within rows 6000 - end\n",
    "       mini1=All_RAW_df.T.iloc[1:].T.iloc[6223:6639].idxmin(axis=0), # index of that min\n",
    "       min2=All_RAW_df.T.iloc[1:].T.iloc[4149:4564].min(axis=0), # min within rows 4000 - 5000\n",
    "       mini2=All_RAW_df.T.iloc[1:].T.iloc[4149:4564].idxmin(axis=0), # index of that min\n",
    "       min3=All_RAW_df.T.iloc[1:].T.iloc[3941:4149].min(axis=0), # min within rows 2282 - 2697\n",
    "       mini3=All_RAW_df.T.iloc[1:].T.iloc[3941:4149].idxmin(axis=0), # index of that min\n",
    "       min4=All_RAW_df.T.iloc[1:].T.iloc[2282:2490].min(axis=0), # min within rows 415 - 830\n",
    "       mini4=All_RAW_df.T.iloc[1:].T.iloc[2282:2490].idxmin(axis=0), # index of that min   \n",
    "       min5=All_RAW_df.T.iloc[1:].T.iloc[2075:2282].min(axis=0), # min within rows 2282 - 2697\n",
    "       mini5=All_RAW_df.T.iloc[1:].T.iloc[2075:2282].idxmin(axis=0), # index of that min\n",
    "       min6=All_RAW_df.T.iloc[1:].T.iloc[0:1038].min(axis=0), # min within rows 415 - 830\n",
    "       mini6=All_RAW_df.T.iloc[1:].T.iloc[0:1038].idxmin(axis=0), # index of that min   \n",
    "        )\n",
    "    \n",
    ")\n",
    "\n",
    "print(dataStats)\n",
    "\n",
    "# select average around minimum value \n",
    "\n",
    "#.rolling(4).mean()\n",
    "\n",
    "\n",
    "\n",
    "# Breaking down what's happening in:\n",
    "# `data.T.iloc[1:].T.iloc[6000:6800].min(axis=0)`\n",
    "# 1) `data.T.iloc[1:].T` - This is a cheeky way of stripping away the first column, \"Wavenumber\",\n",
    "# 1a) `data.T`, transposes the frame i.e. switches rows and columns\n",
    "# 1b) `.iloc[1:]` selects all but the first row (previously all but the first column).\n",
    "# 1c) The final `.T` switches rows and columns back again.\n",
    "# 2) `.iloc[6000:6800]` selects rows at *positions* between 6000 and 6800. We now have a \n",
    "# 2D block of data.\n",
    "# 3) `.min(axis=0)` computes the column-wise minima of the 2D block we just selected, to \n",
    "# give us a 1D Series of numbers.\n",
    "# 3.1) On the next line, `.idxmin(axis=0)` computes the column-wise index of the minimum for \n",
    "# the 2D block we just selected, to give us a 1D Series of index locations.\n",
    "\n",
    "# We want to subtract a linear function from each column in data, that will\n",
    "# connect the minimum values in the two ranges. \n",
    "# We'll use the `apply` method of pd.DataFrame to do that.\n",
    "# Apply operates on rows (or columns if the argument axis is set to 0) of a Dataframe to \n",
    "# compute a function on the elements of that whole row or column.\n",
    "#\n",
    "# We'll define the function that we want to compute.\n",
    "# The first argument is the column or row data themselves and we are free to \n",
    "# provide other data that we need to compute out function.\n",
    "def computeLinearBackground1(values,     # The column values (e.g. Y)\n",
    "                            waveNumber, # The corresponding wavenumbers (e.g. X)\n",
    "                            valueStats  # The dataframe containing the minima and their \n",
    "                                        # indices for each file\n",
    "                 ):\n",
    "    # extract the correct set of minima using the `name` attribute of the `values` series\n",
    "    # to index the `valueStats` frame.\n",
    "    stats = valueStats.loc[values.name, :]\n",
    "    # compute a linear background function\n",
    "    gradient = ((stats.min1 - stats.min2)/(stats.mini1 - stats.mini2))\n",
    "    intercept = stats.min1 - stats.mini1*gradient\n",
    "    linearBackground1 = (gradient * waveNumber.index) + intercept\n",
    "    # subtract that function from the column values\n",
    "    return linearBackground1\n",
    "\n",
    "def computeLinearBackground2(values,    \n",
    "                            waveNumber, \n",
    "                            valueStats  \n",
    "                                        \n",
    "                 ):\n",
    "\n",
    "    stats = valueStats.loc[values.name, :]\n",
    "    gradient = ((stats.min3 - stats.min4)/(stats.mini3 - stats.mini4))\n",
    "    intercept = stats.min3 - stats.mini3*gradient\n",
    "    linearBackground2 = (gradient * waveNumber.index) + intercept\n",
    "    return linearBackground2\n",
    "\n",
    "\n",
    "\n",
    "def computeLinearBackground3(values,   \n",
    "                            waveNumber, \n",
    "                            valueStats  \n",
    "                 ):\n",
    "    \n",
    "    stats = valueStats.loc[values.name, :]\n",
    "    gradient = ((stats.min5 - stats.min6)/(stats.mini5 - stats.mini6))\n",
    "    intercept = stats.min5 - stats.mini5*gradient\n",
    "    linearBackground3 = (gradient * waveNumber.index) + intercept\n",
    "    return linearBackground3\n",
    "\n",
    "# Finally apply our function to the columns of the dataframe (except the wavenumber column)\n",
    "# We specify axis=0 to operate on the columns (confusingly this is referred to as *along*\n",
    "# the index direction in the docs), and pass the first (wavenumber) column and the summary \n",
    "# statistics dataframe, wrapped in a tuple, as the `args` argument.\n",
    "backgroundsA = DR1_A_df.T.iloc[0:].T.apply(computeLinearBackground1, axis=0, args=(DR1_A_df.T.iloc[0], dataStats))\n",
    "backgroundsB = DR1_B_df.T.iloc[0:].T.apply(computeLinearBackground2, axis=0, args=(DR1_B_df.T.iloc[0], dataStats))\n",
    "backgroundsC = DR1_C_df.T.iloc[0:].T.apply(computeLinearBackground3, axis=0, args=(DR1_C_df.T.iloc[0], dataStats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DR1_A_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Baseline correction</u>\n",
    "\n",
    "### data - background subtraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_BC = pd.DataFrame(DR1_A_df - backgroundsA)\n",
    "dataB_BC = pd.DataFrame(DR1_B_df - backgroundsB)\n",
    "dataC_BC = pd.DataFrame(DR1_C_df - backgroundsC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataA_BC_U\n",
    "# dataB_BC_U\n",
    "# dataC_BC_U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Sanity Check\n",
    "\n",
    "We reinsert the Wavenumber that was removed prior to the baseline function aplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_BC.insert(0, 'Wavenumber', All_RAW_df['Wavenumber'])\n",
    "dataB_BC.insert(0, 'Wavenumber', All_RAW_df['Wavenumber'])\n",
    "dataC_BC.insert(0, 'Wavenumber', All_RAW_df['Wavenumber'])\n",
    "\n",
    "backgroundsA.insert(0, 'Wavenumber', All_RAW_df['Wavenumber'])\n",
    "backgroundsB.insert(0, 'Wavenumber', All_RAW_df['Wavenumber'])\n",
    "backgroundsC.insert(0, 'Wavenumber', All_RAW_df['Wavenumber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data_A = dataC_BC.append(dataB_BC).drop_duplicates().reset_index(drop=True)\n",
    "All_data_BC = All_data_A.append(dataA_BC).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All_data_BC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data_BC.to_csv('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Data/DR/DR2_{}_All-scans.csv'.format(XP, date, date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Max Absorbance</u>\n",
    "\n",
    "### Preliminary work\n",
    "\n",
    "A first step in our analysis is to extract and use the maximum absorbance in order to make a first comparison of the frequency shifts with respect to temperature for each sample.\n",
    "\n",
    "#### Range B\n",
    "\n",
    "For range B (combination modes), we need to supress the CO2 signature (that would otherwise contribute to the max A value for this range). As a first guess we aim to supress data from 2390 to 2290 wavenumber\n",
    "\n",
    "#### Range C\n",
    "\n",
    "Concerning range C, we are only aiming for the maximum absorbance of the bending modes but the libration modes have a contribution more important. However the peak is incomplete and we need to supress it. <br>\n",
    "Same approach as previously will be used and we aim to cut the data at wavenumber = 1040 cm-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataB_BC_U = dataB_BC.drop(dataB_BC.index[808:1016])\n",
    "dataC_BC_U = dataC_BC.drop(dataC_BC.index[0:498])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extract max A\n",
    "\n",
    "Here we look for 4 maximum:\n",
    "- two for the range A (1 with the baseline corrected scan and one from the unreduced data, to check that they concord and that the reduction routine does not affect the spectral signature)\n",
    "- one for range B (using dataB_BC_U that excude the CO2 signature)\n",
    "- one for range C (using dataC_BC_U that excude the libration modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data max from unreduced data in range A \n",
    "\n",
    "dataA_Max = pd.DataFrame.from_dict(\n",
    "  dict(maxA0=DR1_A_df.T.iloc[0:].T.iloc[0:].max(axis=0), # min within rows 6000 - end\n",
    "       maxA0i=DR1_A_df.T.iloc[0:].T.iloc[0:].idxmax(axis=0),  \n",
    "\n",
    "        )\n",
    ")\n",
    "\n",
    "#Data max from Baseline Corrected Data in range A \n",
    "\n",
    "dataA_BC_Max = pd.DataFrame.from_dict(\n",
    "  dict(maxA=dataA_BC.T.iloc[1:].T.iloc[1:].max(axis=0), # min within rows 6000 - end\n",
    "       maxAi=dataA_BC.T.iloc[1:].T.iloc[1:].idxmax(axis=0),  \n",
    "\n",
    "        )\n",
    ")\n",
    "\n",
    "#Data max from Baseline Corrected Data in range B\n",
    "\n",
    "dataB_BC_Max = pd.DataFrame.from_dict(\n",
    "  dict(maxB=dataB_BC_U.T.iloc[1:].T.iloc[1:].max(axis=0), # min within rows 6000 - end\n",
    "       maxBi=dataB_BC_U.T.iloc[1:].T.iloc[1:].idxmax(axis=0),  \n",
    "\n",
    "        )\n",
    ")\n",
    "\n",
    "#Data max from Baseline Corrected Data in range C\n",
    "\n",
    "dataC_BC_Max = pd.DataFrame.from_dict(\n",
    "  dict(maxC=dataC_BC_U.T.iloc[1:].T.iloc[1:].max(axis=0), # min within rows 6000 - end\n",
    "       maxCi=dataC_BC_U.T.iloc[1:].T.iloc[1:].idxmax(axis=0),  \n",
    "\n",
    "        )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = All_RAW_df.T.iloc[0]\n",
    "\n",
    "# A DR2\n",
    "\n",
    "dataA_BC_Max = dataA_BC_Max.reset_index()\n",
    "dataA_BC_Max['Name'] = dataA_BC_Max['index']\n",
    "dataA_BC_Max = dataA_BC_Max.T.iloc[1:].T\n",
    "\n",
    "dataA_BC_Max1 = dataA_BC_Max.set_index('maxAi',drop=True)\n",
    "dataA_BC_Max2 = dataA_BC_Max1.join(wavelength, on='maxAi')\n",
    "dataA_BC_Max2 = dataA_BC_Max2.reset_index()\n",
    "dataA_BC_Max_F = dataA_BC_Max2.set_index(dataA_BC_Max.index)\n",
    "dataA_BC_Max_F.rename(columns={'Wavenumber': 'maxAw'}, inplace=True)\n",
    "\n",
    "# A DR1\n",
    "\n",
    "dataA_Max = dataA_Max.reset_index()\n",
    "dataA_Max['Name'] = dataA_Max['index']\n",
    "dataA_Max = dataA_Max.T.iloc[1:].T\n",
    "\n",
    "dataA_Max1 = dataA_Max.set_index('maxA0i',drop=True)\n",
    "dataA_Max2 = dataA_Max1.join(wavelength, on='maxA0i')\n",
    "dataA_Max2 = dataA_Max2.reset_index()\n",
    "dataA_Max_F = dataA_Max2.set_index(dataA_Max.index)\n",
    "dataA_Max_F.rename(columns={'Wavenumber': 'maxA0w'}, inplace=True)\n",
    "\n",
    "# B DR2\n",
    "\n",
    "\n",
    "\n",
    "dataB_BC_Max = dataB_BC_Max.reset_index()\n",
    "dataB_BC_Max['Name'] = dataB_BC_Max['index']\n",
    "dataB_BC_Max = dataB_BC_Max.T.iloc[1:].T\n",
    "\n",
    "dataB_BC_Max1 = dataB_BC_Max.set_index('maxBi',drop=True)\n",
    "dataB_BC_Max2 = dataB_BC_Max1.join(wavelength, on='maxBi')\n",
    "dataB_BC_Max2 = dataB_BC_Max2.reset_index()\n",
    "dataB_BC_Max_F = dataB_BC_Max2.set_index(dataB_BC_Max.index)\n",
    "dataB_BC_Max_F.rename(columns={'Wavenumber': 'maxBw'}, inplace=True)\n",
    "\n",
    "# C DR2\n",
    "\n",
    "dataC_BC_Max = dataC_BC_Max.reset_index()\n",
    "dataC_BC_Max['Name'] = dataC_BC_Max['index']\n",
    "dataC_BC_Max = dataC_BC_Max.T.iloc[1:].T\n",
    "\n",
    "dataC_BC_Max1 = dataC_BC_Max.set_index('maxCi',drop=True)\n",
    "dataC_BC_Max2 = dataC_BC_Max1.join(wavelength, on='maxCi')\n",
    "dataC_BC_Max2 = dataC_BC_Max2.reset_index()\n",
    "dataC_BC_Max_F = dataC_BC_Max2.set_index(dataC_BC_Max.index)\n",
    "dataC_BC_Max_F.rename(columns={'Wavenumber': 'maxCw'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataA_Max_F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Insert column scan number___ \n",
    "\n",
    "to be able to link data_annex with XP_Ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(dataA_BC_Max_F.index.values.tolist()))\n",
    "scan_number = pd.Series(range(1,nscan+1))\n",
    "scan_number.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_BC_Max_F['scan_number'] = scan_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Append to data Annex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anex_df = pd.merge(data_anex_df, dataA_BC_Max_F, on=\"Name\")\n",
    "data_anex_df = pd.merge(data_anex_df, dataA_Max_F, on=\"Name\")\n",
    "data_anex_df = pd.merge(data_anex_df, dataB_BC_Max_F, on=\"Name\")\n",
    "data_anex_df = pd.merge(data_anex_df, dataC_BC_Max_F, on=\"Name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Plotting</u> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(dataA_BC.columns.values.tolist()))\n",
    "\n",
    "ymax =   data_anex_df.iloc[1:,16].astype(float).max()\n",
    "ymin =   data_anex_df.iloc[1:,16].astype(float).min()\n",
    "ymax2 = ymax + 0.01\n",
    "ymin2 = ymin - 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(All_RAW_df.columns.values.tolist()))\n",
    "\n",
    "print(nscan)\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize=(12,6))\n",
    "\n",
    "\n",
    "normalize = mcolors.Normalize(vmin=0, vmax=nscan)\n",
    "colormap = cm.jet\n",
    "i=1\n",
    "\n",
    "for i in range(1,nscan):\n",
    "    \n",
    "    plt.plot(All_data_BC.Wavenumber, All_data_BC['{}_{}_{}'.format(spl, date, i)], color=colormap(normalize(i)))\n",
    "    \n",
    "    i=+1\n",
    "    \n",
    "\n",
    "plt.title('DR2 Baseline Corrected {0}'.format(date))\n",
    "plt.axis([4000,800,-0.05,0.45])\n",
    "plt.xlabel('Wavenumber (cm-1)').set_fontsize(13)\n",
    "plt.ylabel('Absorbance').set_fontsize(13)\n",
    "#ax = fig.gca()\n",
    "plt.grid()\n",
    "#plt.legend()\n",
    "\n",
    "scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "scalarmappaple.set_array(nscan)\n",
    "plt.colorbar(scalarmappaple)\n",
    "\n",
    "#plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_Full-range.png'.format(XP, date, date))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Oh stretch\n",
    "\n",
    "#### Baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(dataA_BC.columns.values.tolist()))\n",
    "\n",
    "nscan2 = nscan//int(2)\n",
    "nscan1 = nscan2*int(5)\n",
    "\n",
    "figure, panels = plt.subplots(figsize=(12, nscan1), ncols=2, nrows=nscan2)\n",
    "\n",
    "for panel, column in zip(panels.flatten(), dataA_BC.columns[1:]):\n",
    "    panel.plot(dataA_BC.Wavenumber, dataA_BC[column], label=\"data\")\n",
    "    panel.plot(dataA_BC.Wavenumber, backgroundsA[column], ls=\"dashed\",  label=\"bg\")\n",
    "\n",
    "    panel.plot(dataA_BC.Wavenumber, dataA_BC[column]+ backgroundsA[column], ls=\"dotted\",  label=\"data+bg (RAW)\")\n",
    "\n",
    "    \n",
    "    \n",
    "    #panel.legend()\n",
    "    panel.set_xlabel(\"wavenumber\")\n",
    "    panel.invert_xaxis()\n",
    "    panel.set_title(column)\n",
    "    panel.legend()\n",
    "    \n",
    "    plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_BCA.png'.format(XP, date, date))\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "#plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  All scans \n",
    "\n",
    "(using scan number - All data)\n",
    "<br>\n",
    "Idea for later : plot OH and maxA together\n",
    "\n",
    "[Marker modification](https://matplotlib.org/stable/api/markers_api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(All_RAW_df.columns.values.tolist()))\n",
    "\n",
    "print(nscan)\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "normalize = mcolors.Normalize(vmin=0, vmax=nscan)\n",
    "colormap = cm.jet\n",
    "i=1\n",
    "\n",
    "for i in range(1,nscan):\n",
    "    \n",
    "    plt.plot(dataA_BC.Wavenumber, dataA_BC['{}_{}_{}'.format(spl, date, i)], color=colormap(normalize(i)))\n",
    "    \n",
    "    i=+1\n",
    "    \n",
    "\n",
    "plt.title('DR2-A Baseline Corrected {0}'.format(date))\n",
    "plt.axis([3800,2800,0,ymax2])\n",
    "plt.xlabel('Wavenumber (cm-1)').set_fontsize(13)\n",
    "plt.ylabel('Absorbance').set_fontsize(13)\n",
    "#ax = fig.gca()\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "scalarmappaple.set_array(nscan)\n",
    "plt.colorbar(scalarmappaple)\n",
    "\n",
    "plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_A.png'.format(XP, date, date))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.A.4b All scans (using dictionnary vale - discrete T)\n",
    "\n",
    "later\n",
    "\n",
    "#### 2.4.A.4 Max Absorbance (peak frequency shift) - Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10,8))\n",
    "\n",
    "for keys, values in Tdictionary.items():\n",
    "\n",
    "    plt.plot(keys, data_anex_df.iloc[values,17], '+', mew=3, ms=12, c=cm.jet(values/nscan),label= str(keys)+\" - \"+str(values+1)+\" - \"+str(int(data_anex_df.iloc[values,17])))\n",
    "    plt.plot(keys, data_anex_df.iloc[values,21], '.', mew=3, ms=12, c=cm.jet(values/nscan),label= str(keys)+\" - \"+str(values+1)+\" - \"+str(int(data_anex_df.iloc[values,21])))\n",
    "\n",
    "plt.title('{0} DR2 OH stretch Peak frequency (DR1-DR2 comparison)'.format(date))\n",
    "#plt.axis([3210,3270])\n",
    "plt.xlabel('Temperature (K)').set_fontsize(13)\n",
    "plt.ylabel('Peak frequency (cm-1)').set_fontsize(13)\n",
    "#ax = fig.gca()\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_PeakA-frequency_wA0.png'.format(XP, date, date))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.A.5 Max Absorbance (peak frequency shift) - Isotherm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Iso == True:\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    for keys, values in Isodic1.items():\n",
    "\n",
    "        plt.plot(keys, data_anex_df.iloc[values,17], '+', mew=3, ms=12, c=cm.jet(values/nscan),label= str(keys)+\" - \"+str(values+1)+\" - \"+str(int(data_anex_df.iloc[values,17])))\n",
    "        \n",
    "    plt.title('{0} DR2 OH stretch Peak frequency Isotherm at {1} K'.format(date,Tiso1))\n",
    "    #plt.axis([3210,3270])\n",
    "    plt.xlabel('Time (h)').set_fontsize(13)\n",
    "    plt.ylabel('Peak frequency (cm-1)').set_fontsize(13)\n",
    "    ax = fig.gca()\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(10))    \n",
    "    #plt.grid()\n",
    "    #plt.legend()\n",
    "\n",
    "\n",
    "    #plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_PeakA-frequency_Iso_{}.png'.format(XP, date, date, Tiso1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Iso == True:\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    for keys, values in Isodic1.items():\n",
    "\n",
    "        plt.plot(keys, data_anex_df.iloc[values,16], '+', mew=3, ms=12, c=cm.jet(values/nscan),label= str(keys)+\" - \"+str(values+1)+\" - \"+str(int(data_anex_df.iloc[values,17])))\n",
    "        \n",
    "    plt.title('{0} DR2 Max A Isotherm at {1} K'.format(date,Tiso1))\n",
    "    #plt.axis([3210,3270])\n",
    "    plt.xlabel('Time (h)').set_fontsize(13)\n",
    "    plt.ylabel('Peak frequency (cm-1)').set_fontsize(13)\n",
    "    ax = fig.gca()\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(10))    \n",
    "    #plt.grid()\n",
    "    #plt.legend()\n",
    "\n",
    "\n",
    "    plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_max_A_Iso_{}.png'.format(XP, date, date, Tiso1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.4.B Comb Bands\n",
    "\n",
    "#### 2.4.B.1 Baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(dataB_BC.columns.values.tolist()))\n",
    "\n",
    "nscan2 = nscan//int(2)\n",
    "nscan1 = nscan2*int(5)\n",
    "\n",
    "figure, panels = plt.subplots(figsize=(10, nscan1), ncols=2, nrows=nscan2)\n",
    "\n",
    "for panel, column in zip(panels.flatten(), dataB_BC.columns[1:]):\n",
    "    panel.plot(dataB_BC.Wavenumber, dataB_BC[column], label=\"data\")\n",
    "    panel.plot(dataB_BC.Wavenumber, backgroundsB[column], ls=\"dashed\",  label=\"bg\")\n",
    "\n",
    "    panel.plot(dataB_BC.Wavenumber, dataB_BC[column] + backgroundsB[column], ls=\"dotted\",  label=\"data+bg (RAW)\")\n",
    "\n",
    "    \n",
    "    \n",
    "    #panel.legend()\n",
    "    panel.set_xlabel(\"wavenumber\")\n",
    "    panel.set_title(column)\n",
    "    panel.invert_xaxis()\n",
    "    panel.legend()\n",
    "    \n",
    "    plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_BCB.png'.format(XP, date, date))\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "#plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.B.3 All scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(All_RAW_df.columns.values.tolist()))\n",
    "\n",
    "print(nscan)\n",
    "\n",
    "\n",
    "f,(ax,ax2) = plt.subplots(1,2,sharey=True)\n",
    "\n",
    "\n",
    "\n",
    "normalize = mcolors.Normalize(vmin=0, vmax=nscan)\n",
    "colormap = cm.jet\n",
    "\n",
    "i=1\n",
    "\n",
    "for i in range(1,nscan):\n",
    "    \n",
    "    ax.plot(dataB_BC_U.Wavenumber, dataB_BC_U['{}_{}_{}'.format(spl, date, i)], color=colormap(normalize(i)))\n",
    "    ax2.plot(dataB_BC_U.Wavenumber, dataB_BC_U['{}_{}_{}'.format(spl, date, i)], color=colormap(normalize(i)))\n",
    "    \n",
    "    i=+1\n",
    "    \n",
    "\n",
    "ax.set_xlim(2800,2390)\n",
    "ax2.set_xlim(2290,1900)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "\n",
    "ax.yaxis.tick_left()\n",
    "ax2.yaxis.set_visible(False)\n",
    "\n",
    "d = .022 # how big to make the diagonal lines in axes coordinates\n",
    "# arguments to pass plot, just so we don't keep repeating them\n",
    "kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
    "ax.plot((1-d,1+d), (-d,+d), **kwargs)\n",
    "ax.plot((1-d,1+d),(1-d,1+d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
    "ax2.plot((-d,+d), (1-d,1+d), **kwargs)\n",
    "ax2.plot((-d,+d), (-d,+d), **kwargs)\n",
    "\n",
    "f.subplots_adjust(wspace=.070)\n",
    "\n",
    "plt.title('DR2-B Baseline Corrected {0}'.format(date))\n",
    "#plt.axis([2800,1900,0,0.015])\n",
    "#plt.xlabel('Wavenumber (cm-1)').set_fontsize(13)\n",
    "#plt.ylabel('Absorbance').set_fontsize(13)\n",
    "#ax = fig.gca()\n",
    "#plt.grid()\n",
    "#plt.legend()\n",
    "\n",
    "scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "scalarmappaple.set_array(nscan)\n",
    "plt.colorbar(scalarmappaple)\n",
    "\n",
    "plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_B.png'.format(XP, date, date))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.B.4 Max A + Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10,8))\n",
    "\n",
    "for keys, values in Tdictionary.items():\n",
    "\n",
    "    plt.plot(keys, data_anex_df.iloc[values,24], '+', mew=3, ms=12, c=cm.jet(values/nscan),label= str(keys)+\" - \"+str(values+1)+\" - \"+str(int(data_anex_df.iloc[values,24])))\n",
    "    #plt.plot(keys, data_anex_df.iloc[values,21], '.', mew=3, ms=12, c=cm.jet(values/nscan),label= str(keys)+\" - \"+str(values+1)+\" - \"+str(int(data_anex_df.iloc[values,21])))\n",
    "\n",
    "plt.title('{0} DR2_B Peak frequency'.format(date))\n",
    "#plt.axis([3210,3270])\n",
    "plt.xlabel('Temperature (K)').set_fontsize(13)\n",
    "plt.ylabel('Peak frequency (cm-1)').set_fontsize(13)\n",
    "#ax = fig.gca()\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_PeakB-frequency.png'.format(XP, date, date))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.4.C Bending\n",
    "\n",
    "#### 2.4.B.1 Baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(dataC_BC.columns.values.tolist()))\n",
    "\n",
    "nscan2 = nscan//int(2)\n",
    "nscan1 = nscan2*int(5)\n",
    "\n",
    "figure, panels = plt.subplots(figsize=(12, nscan1), ncols=2, nrows=nscan2)\n",
    "\n",
    "for panel, column in zip(panels.flatten(), dataC_BC.columns[1:]):\n",
    "    panel.plot(dataC_BC.Wavenumber, dataC_BC[column], label=\"data\")\n",
    "    panel.plot(dataC_BC.Wavenumber, backgroundsC[column], ls=\"dashed\",  label=\"bg\")\n",
    "\n",
    "    panel.plot(dataC_BC.Wavenumber, dataC_BC[column]+ backgroundsC[column], ls=\"dotted\",  label=\"data+bg\")\n",
    "\n",
    "    \n",
    "    \n",
    "    #panel.legend()\n",
    "    panel.set_xlabel(\"wavenumber\")\n",
    "    panel.invert_xaxis()\n",
    "    panel.set_title(column)\n",
    "    panel.legend()\n",
    "    \n",
    "    plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_BCC.png'.format(XP, date, date))\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "#plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.B.3 All scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(dataC_BC.columns.values.tolist()))\n",
    "\n",
    "ymax =   data_anex_df.iloc[1:,23].astype(float).max()\n",
    "ymin =   data_anex_df.iloc[1:,23].astype(float).min()\n",
    "ymax2 = ymax + 0.005\n",
    "ymin2 = ymin - 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(All_RAW_df.columns.values.tolist()))\n",
    "\n",
    "print(nscan)\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "normalize = mcolors.Normalize(vmin=0, vmax=nscan)\n",
    "colormap = cm.jet\n",
    "i=1\n",
    "\n",
    "for i in range(1,nscan):\n",
    "    \n",
    "    plt.plot(dataC_BC.Wavenumber, dataC_BC['{}_{}_{}'.format(spl, date, i)], color=colormap(normalize(i)))\n",
    "    \n",
    "    i=+1\n",
    "    \n",
    "\n",
    "plt.title('DR2-C Baseline Corrected {0}'.format(date))\n",
    "plt.axis([1900,800,0,0.06])\n",
    "plt.xlabel('Wavenumber (cm-1)').set_fontsize(13)\n",
    "plt.ylabel('Absorbance').set_fontsize(13)\n",
    "#ax = fig.gca()\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "scalarmappaple.set_array(nscan)\n",
    "plt.colorbar(scalarmappaple)\n",
    "\n",
    "plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_C.png'.format(XP, date, date))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the unreduced (BC) scans to see if a polynomial would be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscan = len(list(All_RAW_df.columns.values.tolist()))\n",
    "\n",
    "print(nscan)\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "normalize = mcolors.Normalize(vmin=0, vmax=nscan)\n",
    "colormap = cm.jet\n",
    "i=1\n",
    "\n",
    "for i in range(1,nscan):\n",
    "    \n",
    "    plt.plot(dataC_BC_U.Wavenumber, dataC_BC_U['{}_{}_{}'.format(spl, date, i)], color=colormap(normalize(i)))\n",
    "    \n",
    "    i=+1\n",
    "    \n",
    "\n",
    "plt.title('DR2-A Baseline Corrected {0}'.format(date))\n",
    "plt.axis([1900,1030,0,0.06])\n",
    "plt.xlabel('Wavenumber (cm-1)').set_fontsize(13)\n",
    "plt.ylabel('Absorbance').set_fontsize(13)\n",
    "#ax = fig.gca()\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "scalarmappaple.set_array(nscan)\n",
    "plt.colorbar(scalarmappaple)\n",
    "\n",
    "plt.savefig('D:\\DATA-Processing\\PAC\\{}/Samples/{}/Plots/DR/DR2_{}_C_U.png'.format(XP, date, date))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<img style=\"float: right;\" src=\"..\\..\\Docs\\Logo_work_in_progress.svg\" alt=\"logo\" width=\"160px\"/>\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "**Updated On:** 2022-08-24 \n",
    "\n",
    "\n",
    "**Author:** Vincent Deguin, PhD Student.\n",
    "<br>\n",
    " **Contact:** vincent.deguin@open.ac.uk  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
